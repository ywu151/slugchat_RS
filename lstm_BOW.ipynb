{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "def get_word_dic(fre_limit):\n",
    "    word_dic = {}\n",
    "    num = 0\n",
    "    with open('freq_word.txt', 'r') as data_file:\n",
    "        inputs = json.load(data_file)\n",
    "    for couple in inputs:\n",
    "        if couple[1] >= fre_limit:\n",
    "            word_dic[couple[0]] = num\n",
    "            num += 1\n",
    "    return word_dic\n",
    "\n",
    "def words_to_vector(word_dic, words):\n",
    "    vec = [0. for i in range(len(word_dic))]\n",
    "    num = 0\n",
    "    for word in words:\n",
    "        if word in word_dic:\n",
    "            vec[word_dic[word]] += 1.\n",
    "            num += 1.\n",
    "    if num == 0:\n",
    "        return []\n",
    "    return [i / num for i in vec]\n",
    "\n",
    "def get_story_vec(word_dic):\n",
    "    stories = {}\n",
    "    with open('story_seqs.txt', 'r') as data_file:\n",
    "        inputs = json.load(data_file)\n",
    "    for sid in inputs:\n",
    "#         print(sid, inputs[sid]['title'], inputs[sid]['words'])\n",
    "        vec = words_to_vector(word_dic, inputs[sid]['words'])\n",
    "        if len(vec) == 0:\n",
    "            print('empty doc vec')\n",
    "            continue\n",
    "        stories[int(sid)] = dict(title = inputs[sid]['title'], vec = vec)\n",
    "    return stories\n",
    "\n",
    "def generate_data_set(list_len):\n",
    "    with open('view_lists.txt', 'r') as data_file:\n",
    "        inputs = json.load(data_file)\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    for list_json in inputs:\n",
    "        view_list = list_json['list']\n",
    "        if len(view_list) < list_len:\n",
    "            continue\n",
    "        view_set = set(view_list)\n",
    "        for i in range(list_len - 1):\n",
    "            if view_list[i] in view_set:\n",
    "                view_set.remove(view_list[i])\n",
    "        for i in range(list_len - 1, len(view_list)):\n",
    "            x = view_list[i - list_len + 1: i + 1]\n",
    "            outputs.append(x)\n",
    "            labels.append([0., 1.])\n",
    "            ind = randint(0, 699 - len(view_set))\n",
    "            j = 1\n",
    "            x = view_list[i - list_len + 1: i]\n",
    "            while True:\n",
    "                if j not in view_set:\n",
    "                    ind -= 1\n",
    "                    if ind < 0:\n",
    "                        x.append(j)\n",
    "                        outputs.append(x)\n",
    "                        labels.append([1., 0.])\n",
    "                        break\n",
    "                j += 1\n",
    "    return outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132\n",
      "4780 4780\n"
     ]
    }
   ],
   "source": [
    "word_fre_limit = 10\n",
    "view_list_len = 5\n",
    "\n",
    "word_dic = get_word_dic(word_fre_limit)\n",
    "doc_vec_len = len(word_dic)\n",
    "stories = get_story_vec(word_dic)\n",
    "# for i in range(1, 2):\n",
    "#     pprint.pprint(stories[i])\n",
    "list_data, labels = generate_data_set(view_list_len)\n",
    "\n",
    "print(doc_vec_len)\n",
    "print(len(list_data), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4780, 5, 2132)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vecs = [[stories[sid]['vec'] for sid in viewlist]\n",
    "              for viewlist in list_data]\n",
    "np.shape(input_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train_rate = 0.8\n",
    "r_index = list(range(len(list_data)))\n",
    "random.shuffle(r_index)\n",
    "train_x = [input_vecs[i] for i in r_index[:int(len(r_index)*train_rate)]]\n",
    "train_y = [labels[i] for i in r_index[:int(len(r_index)*train_rate)]]\n",
    "test_x = [input_vecs[i] for i in r_index[int(len(r_index)*train_rate):]]\n",
    "test_y = [labels[i] for i in r_index[int(len(r_index)*train_rate):]]\n",
    "test_x_hit = []\n",
    "test_y_hit = []\n",
    "test_x_miss = []\n",
    "test_y_miss = []\n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i][0] < 0.5:\n",
    "        test_x_hit.append(test_x[i])\n",
    "        test_y_hit.append(test_y[i])\n",
    "    else:\n",
    "        test_x_miss.append(test_x[i])\n",
    "        test_y_miss.append(test_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3824\n",
      "3824\n",
      "(5, 2132)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(np.shape(train_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ywu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 50)\n",
      "Initialized\n",
      "Loss at step 0: 0.738346 acc: 0.501308\n",
      "Loss at step 100: 0.665847 acc: 0.888598\n",
      "Loss at step 200: 0.638451 acc: 0.893044\n",
      "Loss at step 300: 0.607974 acc: 0.919718\n",
      "Loss at step 400: 0.572066 acc: 0.938285\n",
      "Loss at step 500: 0.524684 acc: 0.955805\n",
      "Loss at step 600: 0.438081 acc: 0.967573\n",
      "Loss at step 700: 0.316274 acc: 0.970188\n",
      "Loss at step 800: 0.232896 acc: 0.973849\n",
      "Loss at step 900: 0.177761 acc: 0.975418\n",
      "Loss at step 1000: 0.143007 acc: 0.978295\n",
      "Loss at step 1100: 0.119962 acc: 0.981172\n",
      "Loss at step 1200: 0.104005 acc: 0.982741\n",
      "Loss at step 1300: 0.092413 acc: 0.984571\n",
      "Loss at step 1400: 0.083598 acc: 0.985617\n",
      "Loss at step 1500: 0.076641 acc: 0.986663\n",
      "Loss at step 1600: 0.070993 acc: 0.987186\n",
      "Loss at step 1700: 0.066299 acc: 0.988232\n",
      "Loss at step 1800: 0.062310 acc: 0.989278\n",
      "Loss at step 1900: 0.058881 acc: 0.989801\n",
      "Loss at step 2000: 0.055873 acc: 0.990586\n",
      "Loss at step 2100: 0.053193 acc: 0.991109\n",
      "Loss at step 2200: 0.050807 acc: 0.991109\n",
      "Loss at step 2300: 0.048642 acc: 0.991109\n",
      "Loss at step 2400: 0.046687 acc: 0.991109\n",
      "Loss at step 2500: 0.044897 acc: 0.991632\n",
      "Loss at step 2600: 0.043248 acc: 0.991893\n",
      "Loss at step 2700: 0.041724 acc: 0.991893\n",
      "Loss at step 2800: 0.040304 acc: 0.991632\n",
      "Loss at step 2900: 0.038967 acc: 0.991632\n",
      "Loss at step 3000: 0.037709 acc: 0.991893\n",
      "Loss at step 3100: 0.036532 acc: 0.991893\n",
      "Loss at step 3200: 0.035421 acc: 0.991893\n",
      "Loss at step 3300: 0.034374 acc: 0.992678\n",
      "Loss at step 3400: 0.033386 acc: 0.993201\n",
      "Loss at step 3500: 0.032448 acc: 0.993201\n",
      "Loss at step 3600: 0.031558 acc: 0.993462\n",
      "Loss at step 3700: 0.030697 acc: 0.993724\n",
      "Loss at step 3800: 0.029866 acc: 0.993724\n",
      "Loss at step 3900: 0.029057 acc: 0.993985\n",
      "Loss at step 4000: 0.028265 acc: 0.994247\n",
      "Loss at step 4100: 0.027474 acc: 0.994247\n",
      "Loss at step 4200: 0.026685 acc: 0.994247\n",
      "Loss at step 4300: 0.025891 acc: 0.994247\n",
      "Loss at step 4400: 0.025075 acc: 0.994247\n",
      "Loss at step 4500: 0.024234 acc: 0.994247\n",
      "Loss at step 4600: 0.023359 acc: 0.994247\n",
      "Loss at step 4700: 0.022453 acc: 0.994508\n",
      "Loss at step 4800: 0.021533 acc: 0.994508\n",
      "Loss at step 4900: 0.020607 acc: 0.995293\n",
      "Testing Accuracy: 0.979079\n",
      "Testing Hit Accuracy: 0.983437\n",
      "Testing Miss Accuracy: 0.97463\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 50\n",
    "num_steps = 5000\n",
    "n_classes = 2\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device('/cpu:0'):\n",
    "    \n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def dynamicRNN(x, weights, biases):\n",
    "        x = tf.unstack(x, view_list_len, 1)\n",
    "        lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "        outputList, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32) #,sequence_length=10)\n",
    "        output = outputList[-1]\n",
    "        print(output.get_shape())\n",
    "#         outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "        \n",
    "#         outputs = tf.reshape(outputs, [-1, n_hidden])\n",
    "\n",
    "        # Linear activation, using outputs computed above\n",
    "        return tf.matmul(output, weights['out']) + biases['out'], output, states\n",
    "        \n",
    "    x = tf.placeholder(\"float\", [None, view_list_len, doc_vec_len])\n",
    "    y = tf.placeholder(\"float\", [None, n_classes])\n",
    "    inputs = x\n",
    "    labels = y\n",
    "    logits, outputList, finalstates = dynamicRNN(x, weights, biases)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(loss)\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(logits,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        feed_dict = {inputs: train_x, labels: train_y}\n",
    "        _, l, predictions, acc, _output, _states, _w, _b  =session.run(\n",
    "            [optimizer, loss, logits, accuracy, outputList, finalstates, weights, biases],\n",
    "            feed_dict = feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f acc: %f' % (step, l, acc))\n",
    "#       print predictions[:10]\n",
    "#       print train_y[:10]\n",
    "\n",
    "    _acc, _loss, _log = session.run([accuracy, loss,logits],\n",
    "                feed_dict={inputs: test_x, labels: test_y})\n",
    "   \n",
    "    print(\"Testing Accuracy:\", session.run(accuracy,\n",
    "                                           feed_dict={inputs: test_x, labels: test_y}))\n",
    "    print(\"Testing Hit Accuracy:\", session.run(accuracy,\n",
    "                                           feed_dict={inputs: test_x_hit, labels: test_y_hit}))\n",
    "    print(\"Testing Miss Accuracy:\", session.run(accuracy,\n",
    "                                           feed_dict={inputs: test_x_miss, labels: test_y_miss}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out': array([[ 4.1460886 , -0.79982728],\n",
      "       [-0.09262101, -1.8403368 ],\n",
      "       [-0.13673005,  1.13932014],\n",
      "       [ 2.41629648, -0.21761551],\n",
      "       [ 0.86916351, -0.61454934],\n",
      "       [ 0.13271935, -0.31958792],\n",
      "       [ 0.87902445,  0.70441228],\n",
      "       [-1.76063371,  0.17705514],\n",
      "       [-1.79775691, -0.19743636],\n",
      "       [-0.78480625,  0.82893419],\n",
      "       [ 0.5669027 ,  0.37268162],\n",
      "       [-0.3448348 ,  1.5058713 ],\n",
      "       [ 1.76369178, -0.53208447],\n",
      "       [ 1.2716819 , -1.60101426],\n",
      "       [ 0.81526417,  0.40886939],\n",
      "       [ 0.76217526, -0.47564808],\n",
      "       [-1.44761491, -1.5417738 ],\n",
      "       [-0.12595981,  1.92044282],\n",
      "       [-2.25187802, -0.30091959],\n",
      "       [-2.14260602,  1.54209197],\n",
      "       [ 0.46331334,  0.38964435],\n",
      "       [ 0.18812354,  1.69453824],\n",
      "       [-0.23647772,  1.16230381],\n",
      "       [ 0.49304643,  0.97173315],\n",
      "       [-0.01465913,  1.77578568],\n",
      "       [ 1.1485281 ,  0.01627538],\n",
      "       [-0.40430701, -0.32460755],\n",
      "       [ 0.23986933, -0.49009082],\n",
      "       [ 0.08291832,  0.36585301],\n",
      "       [ 1.47815156, -0.4063583 ],\n",
      "       [ 1.48900509, -0.26313108],\n",
      "       [ 1.19187772, -0.23030093],\n",
      "       [-0.32382932,  0.88320047],\n",
      "       [-0.6008997 ,  1.23857152],\n",
      "       [-1.28806913,  0.12227575],\n",
      "       [-2.60633159, -0.65861076],\n",
      "       [-0.69582319,  0.85671622],\n",
      "       [ 0.14622951,  0.32997772],\n",
      "       [ 0.88563138, -1.91149187],\n",
      "       [ 1.09782338, -1.70996559],\n",
      "       [ 1.26755738, -0.25732231],\n",
      "       [ 0.559753  , -1.75340271],\n",
      "       [ 0.41314262, -0.80277169],\n",
      "       [ 0.21037745,  2.21303105],\n",
      "       [-0.15070103,  0.15628491],\n",
      "       [ 0.19482271,  0.4700225 ],\n",
      "       [-0.40593988,  1.29496515],\n",
      "       [-1.36391592,  1.33015573],\n",
      "       [-1.31517613,  1.08189166],\n",
      "       [ 0.28873098, -0.89381075]], dtype=float32)} {'out': array([ 0.27340978, -0.34929436], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(_w, _b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97907948, 0.096978597)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_acc, _loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.34424138,  4.78389645],\n",
       "       [-2.11619663,  4.27642393],\n",
       "       [-1.0538218 ,  4.51326609],\n",
       "       [-2.11619663,  4.27642393],\n",
       "       [ 4.36826944, -2.0003252 ],\n",
       "       [ 8.52097702, -4.66331625],\n",
       "       [ 5.3442049 , -2.29197764],\n",
       "       [-0.79571134,  3.4618299 ],\n",
       "       [ 5.74861383, -2.86019087],\n",
       "       [-1.41135812,  4.17305374]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_log[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
