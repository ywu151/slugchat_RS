{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_story = {}\n",
    "for i in range(1, 701):\n",
    "    fre_story[i] = 0\n",
    "\n",
    "playlists = {}\n",
    "with open('view_lists_finial.txt', 'r') as data_file:\n",
    "    playlists = json.load(data_file)\n",
    "    \n",
    "for playlist in playlists:\n",
    "    for sid in playlists[playlist]['list']:\n",
    "        fre_story[sid] += 1\n",
    "\n",
    "sid_to_title = {}\n",
    "\n",
    "db = MySQLdb.connect(\"slugchat-test.lorabit.com\", \"root\", \"password\", \"slugchat\")\n",
    "cursor = db.cursor()\n",
    "\n",
    "sql = \"SELECT storyId, entityName FROM slugchat.tbl_stories\"\n",
    "cursor.execute(sql)\n",
    "results = cursor.fetchall()\n",
    "for row in results:\n",
    "    sid_to_title[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精卫填海\n",
      "小老鼠的敲敲长\n",
      "泡泡糖飞船\n",
      "圣诞老人也收到了礼物\n",
      "榨菜鼻子\n",
      "在回家的路上\n",
      "月亮婆婆值夜班\n",
      "分大苹果\n",
      "懂礼貌的小兔\n",
      "百鸟朝凤\n",
      "施洋搓脚夜读\n",
      "女娲造人\n",
      "刻舟求剑\n",
      "晚安月亮\n",
      "三只熊过圣诞节\n",
      "圣诞小故事\n",
      "圣诞袜的故事\n",
      "元宵节的由来\n",
      "盘古开天\n",
      "观音送画\n",
      "中元节的由来\n",
      "炎帝击石生火\n",
      "孟姜女哭长城\n",
      "端午节的来历\n",
      "过年的来历\n",
      "重阳节的来历\n",
      "消失的树枝\n",
      "草地上的罐头\n",
      "潘和伏秃龙\n",
      "沈从文知错就改\n",
      "牛顿的一生\n",
      "刘勰佛殿借读\n",
      "林肯干活赔书\n",
      "富兰克林发明了避雷针\n",
      "曹禺真读书假洗澡\n",
      "车胤囊萤夜读\n",
      "达尔文观察趣事\n",
      "爱因斯坦的读书法\n",
      "不穿布鞋的贺龙\n",
      "小兔和小羊\n",
      "胆大的老虎\n",
      "机智的小绒布鸭\n",
      "坏蛋那边跑\n",
      "虹小仙子和小白兔\n",
      "一个老铁匠\n",
      "小麻雀模仿苍鹰\n",
      "三个金色的雕塑\n",
      "河马先生的魔术\n",
      "房顶上的大蘑菇\n",
      "红红的苹果\n",
      "生命泉\n",
      "老妈妈\n",
      "榛树枝\n",
      "小海兔的故事\n",
      "圣母的小酒杯\n",
      "小鲤鱼住新房\n",
      "三座房子里的小蜜蜂\n",
      "狒狒的雨\n",
      "会说话的卷心菜\n",
      "一丝不苟\n",
      "亡羊补牢\n",
      "水落石出\n",
      "水滴石穿\n",
      "杀鸡取蛋\n",
      "塞翁失马\n",
      "千里之行,始于足下\n",
      "磨杵成针\n",
      "惊弓之鸟\n",
      "半途而废\n",
      "百发百中\n",
      "蛇与黄鼠狼打架\n",
      "蛇的尾巴与身体\n",
      "鹞子与蛇\n",
      "蝮蛇和水蛇\n",
      "受气的蛇\n",
      "神像与木匠\n",
      "哲学家和蚂蚁\n",
      "宙斯和猴子\n",
      "英雄\n",
      "赫拉克勒斯与雅典娜\n",
      "宙斯做判官\n",
      "宙斯与乌龟\n",
      "宙斯与善\n",
      "宙斯与蛇\n",
      "宙斯与阿波罗\n",
      "宙斯与狐狸\n",
      "赫耳墨斯与地神\n",
      "樵夫与橡树\n",
      "橡树与宙斯\n",
      "农夫与鹰\n",
      "旅行的第欧根尼\n",
      "第欧根尼与秃子\n",
      "演说家\n",
      "黄鼠狼与锉刀\n",
      "金丝雀与蝙蝠\n",
      "猎人与樵夫\n",
      "女人与酗酒的丈夫\n",
      "三只公牛与狮子\n",
      "人与狐狸\n",
      "人与宙斯\n",
      "青蛙邻居\n",
      "骗子\n",
      "农夫与狼\n",
      "发现金狮子的人\n",
      "遇难的人\n",
      "农夫和树\n",
      "狡猾的人\n",
      "农夫与命运女神\n",
      "还不了愿的人\n",
      "狐狸和笼里的狮子\n",
      "狐狸和猴子大王\n",
      "丈夫与妻子\n",
      "狐狸和狗\n",
      "狐狸和鳄鱼\n",
      "磨坊主、儿子与驴\n",
      "天文学家\n",
      "赫耳墨斯与雕刻家\n",
      "吹牛的运动员\n",
      "河边的狐狸\n",
      "女主人与侍女们\n",
      "牧人与海\n",
      "饥饿的狗\n",
      "三个手艺人\n",
      "小胖猪哭了\n",
      "小蜜蜂与花儿\n",
      "世界上最可爱的人\n",
      "漂亮的小狗\n",
      "天空要塌下来了\n",
      "寻猫布告\n",
      "鼹鼠找面包\n",
      "小熊生日会\n",
      "小蜗牛请医生\n",
      "蜗牛的小灯笼\n",
      "罐头小人\n",
      "十二门徒\n",
      "夏娃的孩子们\n",
      "十二个跳舞的公主\n",
      "来自天堂的连枷\n",
      "甜粥\n",
      "土地神\n",
      "女水妖\n",
      "石竹花\n",
      "霍勒大妈\n",
      "坟中的穷少年\n",
      "寿命\n",
      "鸬鹚和戴胜\n",
      "天堂里的农夫\n",
      "懒鬼哈利和特琳娜\n",
      "挑媳妇\n",
      "两个费迪南\n",
      "技艺高超的猎人\n",
      "约丽丹和约雷德尔\n",
      "侏儒妖\n",
      "海尔是个大坏蛋\n",
      "天堂之路\n",
      "智者神偷\n",
      "钉子\n",
      "鲽鱼\n",
      "林中小屋\n",
      "画眉嘴国王\n",
      "爱人罗兰\n",
      "谜语\n",
      "汉赛尔与格莱特\n",
      "三个纺纱女\n",
      "我当建筑师\n",
      "毛毛虫历险记\n",
      "离家的小狗\n",
      "蜗牛的友谊\n",
      "老奶奶和小花猫\n",
      "一双鞋的故事\n",
      "小蛋壳的故事\n",
      "美丽的青蛙公主\n",
      "野猪先生的对不起\n",
      "小胖熊半夜历险记\n",
      "杂技表演大赛\n",
      "电话里传来的暖气\n",
      "贪吃的小狮子\n",
      "小个子的竺可桢\n",
      "路灯下的读书人\n",
      "长大以后就造桥\n",
      "女子篮球赛\n",
      "唱歌的鸟\n",
      "安徒生的童年\n",
      "父亲育儿\n",
      "萨维奇的一生\n",
      "迪生借力\n",
      "两个小坏蛋\n",
      "好交易\n",
      "天真烂漫\n",
      "人杰地灵\n",
      "千变万化\n",
      "祁红之父\n",
      "吾谓耕者比我高\n",
      "感恩图报\n",
      "剪头发\n",
      "周总理的幽默\n",
      "渔翁\n",
      "仙山的传说\n",
      "勇除三头妖\n",
      "勇敢的奇尼\n",
      "谢端与白水素女\n",
      "打鱼郎治服鱼精\n",
      "神奇的桦皮篓\n",
      "年息花的传说\n",
      "龙灯\n",
      "黄帝主宰宇宙\n",
      "智多星与糊涂神\n",
      "洛水女神\n",
      "新任主宰神帝\n",
      "锦线女龙\n",
      "管家龙\n",
      "龙头金钗\n",
      "龙外孙的故事\n",
      "吹萧会龙女\n",
      "月亮阴晴圆缺\n",
      "孔雀公主\n",
      "酿酒始祖杜康\n",
      "姜太公钓鱼\n",
      "湘妃竹的由来\n",
      "夸父追日\n",
      "邯郸学步\n",
      "钻木取火\n",
      "望洋兴叹\n",
      "祖母\n",
      "大逆不道\n",
      "一滴水\n",
      "得过且过\n",
      "跳高者\n",
      "杜鹃啼血\n",
      "舞吧,舞吧,我的玩偶\n",
      "月下老人\n",
      "梦神\n",
      "两兄弟\n",
      "凤凰\n",
      "沉香救母\n",
      "茶壶\n",
      "后羿射日\n",
      "只怕迟了一分钟\n",
      "谁最先\n",
      "一只骄傲的小鸡\n",
      "叶之吟\n",
      "兄弟\n",
      "小古斯塔娃的早餐\n",
      "山的回音\n",
      "让鸟儿自由\n",
      "浪花的任务\n",
      "剪羊毛的趣味\n",
      "叶儿与风儿\n",
      "聪明的小牧童\n",
      "爱打针的溪溪\n",
      "宝宝洗澡歌\n",
      "不爱洗澡的小猪\n",
      "好饿好饿的毛毛虫\n",
      "不爱吃饭的贝贝\n",
      "宝宝吃饭\n",
      "挑食的小贝贝\n",
      "洗澡真舒服\n",
      "拇指姑娘\n",
      "狼与小羊\n",
      "城堡上的一幅画\n",
      "织补针\n",
      "荞麦\n",
      "顽皮的孩子\n",
      "雏菊\n",
      "踩着面包走的女孩\n",
      "叶公好龙\n",
      "九斤姑娘\n",
      "盲人摸象\n",
      "嫦娥奔月\n",
      "画蛇添足\n",
      "画饼充饥\n",
      "囫囵吞枣\n",
      "华盛顿砍树\n",
      "曹冲称象\n",
      "司马光砸缸\n",
      "匡衡凿壁偷光\n",
      "孔融让梨\n",
      "列宁小的时候\n",
      "胆识过人的毛泽东\n",
      "抗日英雄王二小\n",
      "运盐的驴子\n",
      "披着狮皮的驴\n",
      "挤牛奶的姑娘\n",
      "鹅与鹤\n",
      "樵夫与赫耳墨斯\n",
      "睡美人\n",
      "莴苣姑娘\n",
      "猛虎上当记\n",
      "井底之蛙\n",
      "对牛弹琴\n",
      "守株待兔\n",
      "乌龟与鹰\n",
      "穷人和富人\n",
      "菊花仙子\n",
      "卖火柴的小女孩\n",
      "萝卜\n",
      "星星银元\n",
      "聪明的格蕾特\n",
      "野兔和刺猬\n",
      "老鼠排第一名\n",
      "小猴和小熊的自行车\n",
      "月亮\n",
      "白石化成羊\n",
      "谁跟小羚羊去避暑\n",
      "马头琴的来历\n",
      "小猴子下山\n",
      "小母鸡欢欢\n",
      "山里来的小老虎\n",
      "燕子与乌鸦\n",
      "一根羽毛\n",
      "瞎子和小野兽\n",
      "风与太阳\n",
      "三个马大哈\n",
      "红蚂蚁的节日礼物\n",
      "大头儿子与猫黄黄\n",
      "种树的老爷爷\n",
      "大熊逃呀逃\n",
      "猫妈妈搬家\n",
      "十二生肖的故事\n",
      "驴子的坏主意\n",
      "毛毛和长鼻子树\n",
      "红蚂蚁和黑蚂蚁\n",
      "勇敢的小刺猬\n",
      "河马大叔开店\n",
      "三个好朋友\n",
      "后羿与嫦娥\n",
      "苍蝇与蜜\n",
      "八卦田\n",
      "叼着肉的狗\n",
      "狼和狐狸\n",
      "咪咪的钓鱼竿\n",
      "两个酒罐\n",
      "花羽毛小松鸡\n",
      "雕花弓\n",
      "小蝌蚪画画\n",
      "老鼠家族\n",
      "猪和牛\n",
      "大笨牛行大运\n",
      "呼噜猫和阿猜狗\n",
      "金发姑娘和三只熊\n",
      "河狸智斗鳄鱼\n",
      "一根了不起的木棍\n",
      "乌龟飞天\n",
      "萤火虫找朋友\n",
      "狮子烫发\n",
      "机智的鸡\n",
      "谁去给猫儿挂铃铛\n",
      "剪刀大侠\n",
      "小鸡吱吱\n",
      "小熊穿皮鞋\n",
      "戴项链的比赛\n",
      "大肚子蝈蝈\n",
      "黑熊换鸡蛋\n",
      "玩具回家了\n",
      "冰孩儿\n",
      "射水鱼尾尾\n",
      "豆豆兵去打仗\n",
      "小灰狼\n",
      "小老鼠咪咪打电话\n",
      "两只毛毛熊\n",
      "健忘草\n",
      "箭猪和他的伙伴\n",
      "小公鸡学吹喇叭\n",
      "蚂蚁报恩\n",
      "真假小白兔\n",
      "最好吃的蛋糕\n",
      "要下雨了\n",
      "小白兔和小灰兔\n",
      "这个办法真好\n",
      "小公主和蛇\n",
      "奇怪的镜子\n",
      "逃家小兔\n",
      "猜猜我有多爱你\n",
      "圣诞老人的传说\n",
      "圣诞树的故事\n",
      "国王的黄金梦\n",
      "弄巧成拙\n",
      "大公无私\n",
      "士兵与乌鸦\n",
      "捕到石头的渔夫\n",
      "白新娘和黑新娘\n",
      "千皮兽\n",
      "金山王\n",
      "袋鼠与笼子\n",
      "三个小矮人\n",
      "空城计的故事\n",
      "两桃杀三士\n",
      "完璧归赵\n",
      "三生有幸\n",
      "气壮山河\n",
      "华而不实\n",
      "汗流浃背\n",
      "草船借箭\n",
      "戏弄关帝老爷\n",
      "百折不挠\n",
      "白蛇传\n",
      "鹦鹉洲的由来\n",
      "周穆王西游\n",
      "兴高采烈\n",
      "天下无双\n",
      "道听途说\n",
      "退避三舍\n",
      "珍贵的硬币\n",
      "沙子与石头\n",
      "蜡烛\n",
      "手术费一杯牛奶\n",
      "老狐狸和鸭子\n",
      "玛丽和洋娃娃\n",
      "哈里和可怕的怪物\n",
      "小面包里的银币\n",
      "沙漏的启示\n",
      "巨人和裁缝\n",
      "三颗星星\n",
      "信封里的琪琪\n",
      "大公鸡和漏嘴巴\n",
      "洗澡\n",
      "小星星洗澡\n",
      "二贝和三贝\n",
      "贝哈哈博士的假牙\n",
      "东施效颦\n",
      "杰克伦敦的饿狼式读书法\n",
      "彭总穿便服见教师\n",
      "屈原洞中苦读\n",
      "口渴的鸽子\n",
      "马槽中的狗\n",
      "太阳结婚\n",
      "牛郎织女\n",
      "走进天堂的裁缝\n",
      "三兄弟\n",
      "狐狸和马\n",
      "两个神秘的小鞋匠\n",
      "三个懒汉\n",
      "农夫与魔鬼\n",
      "忠狗送信记\n",
      "懒猪大逃亡\n",
      "聪明的蛇医生\n",
      "蛇报恩\n",
      "三种语言\n",
      "农夫与他的儿子们\n",
      "小蟹与母蟹\n",
      "月亮和她妈妈\n",
      "乌龟与兔\n",
      "春节的来历\n",
      "黄帝乘龙升天\n",
      "两只打架的公鸡\n",
      "懒纺妇\n",
      "大坝告急\n",
      "飞毛腿白兔\n",
      "象鼻子桥\n",
      "闻鸡起舞\n",
      "声东击西孙膑\n",
      "鲁迅的故事\n",
      "孔子不耻下问\n",
      "古代大诗人李白\n",
      "曹操\n",
      "望娘滩\n",
      "自相矛盾\n",
      "朝三暮四\n",
      "义无反顾\n",
      "一诺千金\n",
      "一鸣惊人\n",
      "一鼓作气\n",
      "一发千钧\n",
      "事半功倍\n",
      "三顾茅庐\n",
      "杞人忧天\n",
      "抛砖引玉\n",
      "骄兵必败\n",
      "开诚布公\n",
      "赴汤蹈火\n",
      "奉公守法\n",
      "分庭抗礼\n",
      "反客为主\n",
      "对症下药\n",
      "雕虫小技\n",
      "乘风破浪\n",
      "才高八斗\n",
      "不入虎穴,焉得虎子\n",
      "不耻下问\n",
      "闭门思过\n",
      "杯弓蛇影\n",
      "按图索骥\n",
      "安居乐业\n",
      "狐狸和猴子争论家世\n",
      "狐狸和狮子\n",
      "鹿与狮子\n",
      "肚胀的狐狸\n",
      "老狮子\n",
      "守财奴\n",
      "燕子与蟒蛇\n",
      "小孩和苎麻\n",
      "赌鬼汉塞尔\n",
      "池中水妖\n",
      "没有手的姑娘\n",
      "小弟弟和小姐姐\n",
      "四面楚歌\n",
      "沧海桑田\n",
      "安然无羔\n",
      "飞鸟惊蛇\n",
      "天衣无缝\n",
      "亚当与夏娃\n",
      "小心翼翼\n",
      "赤膊上阵\n",
      "奋不顾身\n",
      "太阳和风的争吵\n",
      "盲人最感激谁\n",
      "贝多芬失聪\n",
      "瓦特研究蒸汽\n",
      "侯宝林抄书\n",
      "宋濂冒雪访师\n",
      "厉归真学画虎\n",
      "玄奘苦学佛法\n",
      "欧阳修\n",
      "陆游书巢勤学\n",
      "墨汁当小菜\n",
      "朱德给老人让座\n",
      "李晟练成神箭手\n",
      "狐狸和豹\n",
      "蚂蚁与鸽子\n",
      "小孩与栗子\n",
      "小猪与羊群\n",
      "七岁咏鹅骆宾王\n",
      "狐狸和鹤\n",
      "小母牛与公牛\n",
      "司马光警枕励志\n",
      "范仲淹\n",
      "狼与母山羊\n",
      "毛泽东的故事\n",
      "猫和鼠\n",
      "蜜蜂与宙斯\n",
      "黑格尔逸闻趣事\n",
      "傻瓜汉斯\n",
      "老鼠,小鸟和香肠\n",
      "郑人买履\n",
      "笨鸟先飞\n",
      "八仙过海\n",
      "农夫与蛇\n",
      "居里夫人\n",
      "祖父和孙子\n",
      "小羊羔与小鱼儿\n",
      "木木和木儿\n",
      "老鼠娶亲\n",
      "大自然的闹钟\n",
      "歧途亡羊\n",
      "小鹿与他的父亲\n",
      "蚂蚁与屎壳郎\n",
      "寡妇与母鸡\n",
      "我的爸爸叫焦尼\n",
      "报佳音的由来\n",
      "杀人凶手\n",
      "狼与马\n",
      "狮子与公牛\n",
      "过河拆桥\n",
      "高枕无忧\n",
      "覆水难收\n",
      "分道扬镳\n",
      "返老还童\n",
      "不远千里\n",
      "九牛一毛\n",
      "不自量力\n",
      "高山流水\n",
      "天罗地网\n",
      "一言九鼎\n",
      "海角天涯\n",
      "万死不辞\n",
      "呆若木鸡\n",
      "举一反三\n",
      "不可多得\n",
      "鸡鸣狗盗\n",
      "李四光的故事\n",
      "拿破仑\n",
      "那个伟大的倒霉蛋\n",
      "李密牛角挂书\n",
      "尔尼雪夫斯基\n",
      "高尔基救书\n",
      "张广厚吃书\n",
      "沈括看桃花\n",
      "唐伯虎潜心学画\n",
      "管宁割席分坐\n",
      "宋濂\n",
      "徐文长智慧故事\n",
      "李远哲\n",
      "齐白石\n",
      "男高音歌唱家廖昌永\n",
      "少年包拯学断案\n",
      "木匠的祖师鲁班\n",
      "张衡制造地动仪\n",
      "中华医神华佗\n",
      "孩子和青蛙\n",
      "渔夫与大鱼和小鱼\n",
      "牧人与野山羊\n",
      "鹰与乌鸦\n",
      "妙拟华章柳宗元\n",
      "年少志高岳飞\n",
      "铁道专家詹天佑\n",
      "老鼠与黄鼠狼\n",
      "驴子和驴夫\n",
      "狼与牧羊人\n",
      "童年时代的鲁迅\n",
      "一代名人郭沫若\n",
      "贼和看家狗\n",
      "青蛙求王\n",
      "为中华崛起而读书周恩来\n",
      "妙算惊人华罗庚\n",
      "生金蛋的鹅\n",
      "严谨治学竺可桢\n",
      "马克思的故事\n",
      "山羊与牧羊人\n",
      "瓦特的成长\n",
      "阳春白雪\n",
      "扬扬得意\n",
      "千里送鹅毛\n",
      "远水不救近火\n",
      "杀鸡吓猴\n",
      "三人成虎\n",
      "芝兰玉树\n",
      "猫头鹰\n",
      "老太婆和羊\n",
      "马和鹿\n",
      "狼与老太婆\n",
      "驴子与蝉\n",
      "吴孟举遇仙\n",
      "茶壶\n",
      "兔子新娘\n",
      "狼和人\n",
      "狐狸和猫\n",
      "十二个懒汉\n",
      "万事通大夫\n",
      "白雪皇后\n",
      "水晶球\n",
      "虱子和跳蚤\n",
      "麦草,煤块和豆子\n",
      "胸有成竹\n",
      "孺子可教\n",
      "牧人和丢失的牛\n",
      "行人与梧桐树\n",
      "挂铃的狗\n",
      "捕鸟人和冠雀\n",
      "被狗咬的人\n",
      "人与同行的狮子\n",
      "争吵的儿子们\n",
      "受伤的狼与羊\n",
      "猴子与海豚\n",
      "老太婆与医生\n",
      "鼹鼠\n",
      "农夫和鹳\n",
      "渔夫与小梭鱼\n",
      "兔与青蛙\n",
      "灯\n",
      "断尾的狐狸\n",
      "大力神和车夫\n",
      "胃与脚\n",
      "兔子和猎狗\n",
      "滥竽充数\n",
      "牛栏里的鹿\n",
      "朋友与熊\n",
      "一只眼睛的鹿\n",
      "骆驼与宙斯\n",
      "两虎相斗\n",
      "病鹿\n",
      "吹箫的渔夫\n",
      "公鸡和宝玉\n",
      "老猎狗\n",
      "徒劳的乌鸦\n",
      "小男孩与蝎子\n",
      "狼与鹭鸶\n",
      "total rare stories number:  666\n"
     ]
    }
   ],
   "source": [
    "rare_stories = set()\n",
    "for i in range(1, 701):\n",
    "    if fre_story[i] == 0:\n",
    "        rare_stories.add(i)\n",
    "        print(sid_to_title[i])\n",
    "\n",
    "print('total rare stories number: ', len(rare_stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 21 title: 大禹治水 Fre: 36\n",
      "No 61 title: 愚公移山 Fre: 232\n",
      "No 127 title: 小兔学长跑 Fre: 36\n",
      "No 163 title: 小马过河 Fre: 68\n",
      "No 242 title: 揠苗助长 Fre: 244\n",
      "No 254 title: 乌鸦喝水 Fre: 30\n",
      "No 271 title: 青蛙王子 Fre: 226\n",
      "No 274 title: 掩耳盗铃 Fre: 234\n",
      "No 281 title: 狐假虎威 Fre: 270\n",
      "No 297 title: 灰姑娘 Fre: 460\n",
      "No 298 title: 狼和七只小山羊 Fre: 324\n",
      "No 302 title: 丑小鸭 Fre: 262\n",
      "No 306 title: 女娲补天 Fre: 240\n",
      "No 308 title: 小毛驴 Fre: 22\n",
      "No 313 title: 神笔马良 Fre: 370\n",
      "No 314 title: 猪八戒吃西瓜 Fre: 340\n",
      "No 316 title: 小蝌蚪找妈妈 Fre: 408\n",
      "No 321 title: 小燕子吉吉 Fre: 32\n",
      "No 328 title: 小水壶迷路 Fre: 34\n",
      "No 333 title: 拔萝卜 Fre: 20\n",
      "No 346 title: 龟兔赛跑 Fre: 350\n",
      "No 347 title: 小猫钓鱼 Fre: 106\n",
      "No 348 title: 狼来了 Fre: 340\n",
      "No 353 title: 小红帽 Fre: 512\n",
      "No 355 title: 三只小猪 Fre: 360\n",
      "No 371 title: 小猪照镜子 Fre: 30\n",
      "No 378 title: 小骡子是谁的孩子 Fre: 38\n",
      "No 379 title: 小树叶贺卡 Fre: 30\n",
      "No 380 title: 小猪的礼物 Fre: 30\n",
      "No 382 title: 懒熊买西瓜 Fre: 282\n",
      "No 385 title: 小熊买糖果 Fre: 36\n",
      "No 394 title: 小青蛙的故事 Fre: 42\n",
      "No 576 title: 精卫填海 Fre: 228\n",
      "No 581 title: 狐狸和葡萄 Fre: 306\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 701):\n",
    "    if fre_story[i] > 0:\n",
    "        print('No %d title: %s Fre: %d' % (i, sid_to_title[i], fre_story[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[348, 297, 242, 581, 576, 306, 353, 281, 274, 316, 61, 382, 298, 346, 355, 314, 302, 313]\n",
      "[297, 353, 355, 314, 348, 302, 316, 271, 297, 298, 346, 353, 382, 581, 313, 242, 576, 61, 281, 306]\n",
      "[302, 313, 347, 348, 355, 382, 346, 581, 353, 297, 321, 385, 127, 328, 379, 394, 163, 378, 316]\n",
      "[298, 348, 314, 355, 281, 581, 576, 313, 347, 302, 353, 271, 297]\n",
      "[581, 271, 302, 298, 316, 355, 297, 348, 353, 346]\n",
      "[271, 353, 313, 297, 274, 302, 581, 298, 297, 316, 346, 314, 353, 348, 355]\n",
      "[298, 271, 314, 313, 297, 348, 353, 382, 302]\n",
      "[271, 298, 382, 581, 313, 346, 281, 353, 348, 314, 316, 355]\n",
      "[313, 314, 581, 346, 348, 382, 316]\n",
      "[347, 576, 302, 274, 281, 382, 581, 242, 313, 298, 346, 348, 297]\n",
      "[21, 347, 163, 271, 394, 385, 348, 297, 314, 313, 346, 382, 581, 306, 353, 298, 355, 281, 316, 61]\n",
      "[61, 576, 581, 302, 313, 348, 316, 281, 353, 353, 355, 314]\n",
      "[347, 313, 353, 298, 355]\n",
      "[271, 355, 281, 274, 242, 313, 297, 346, 348, 353, 314, 316, 302]\n",
      "[271, 302, 298, 297, 314, 355, 353]\n",
      "[316, 355, 314, 353, 348, 297, 346, 298, 313, 581, 382, 242, 281, 274, 306, 61, 576]\n",
      "[347, 61, 271, 355, 298, 353, 382, 346, 314, 297, 348]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353]\n",
      "[355, 346, 347, 316, 271, 297, 353]\n",
      "[347, 313, 306, 581, 302, 346, 348, 353, 297, 355, 316, 314]\n",
      "[302, 297, 271, 353, 348]\n",
      "[347, 316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 271, 353, 297, 581, 576, 306, 281, 242, 61, 316, 274, 313, 348, 382, 346, 302, 298, 353, 314, 355]\n",
      "[254, 61, 576, 306, 281, 274, 242, 581, 382, 298, 313, 346, 297, 348, 314, 353, 355, 316]\n",
      "[302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[297, 302, 346, 314, 316]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 61, 316]\n",
      "[271, 281, 297, 348, 302, 353, 314, 316]\n",
      "[576, 306, 61, 581, 242, 313, 297, 346, 348, 353]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353]\n",
      "[328, 394, 163, 378, 316]\n",
      "[333, 308, 298, 281, 355, 271, 346, 581, 348, 353, 353, 274, 302, 297, 316]\n",
      "[297, 61, 306, 382, 348, 298, 271, 576, 353, 274, 281, 242, 581, 313, 302, 316, 353, 355, 346]\n",
      "[297, 242, 314, 313, 346, 348, 163]\n",
      "[581, 298, 297, 348, 353, 346, 316]\n",
      "[316, 333, 353, 316, 308]\n",
      "[302, 382, 298, 313, 581, 297, 348, 353, 314, 346, 355, 316]\n",
      "[314, 581, 346, 308, 316, 333, 313, 348]\n",
      "[61, 306, 581, 271, 346, 313, 298, 302, 297, 355, 348, 353, 314]\n",
      "[353, 302, 382, 581, 313, 346, 348]\n",
      "[333, 297, 271, 581, 313, 297, 302, 353, 355]\n",
      "[298, 297, 346, 348, 313, 355, 353, 314, 316]\n",
      "[254, 353, 281, 382, 314, 302, 581, 298, 346, 348, 355, 353, 316]\n",
      "[281, 382, 313, 302, 346, 314, 316]\n",
      "[347, 353, 271, 302, 297, 163]\n",
      "[316, 242, 127, 163, 306, 281, 302, 298, 313, 346, 297, 348]\n",
      "[61, 576, 306, 281, 274, 297, 346, 302, 348, 314, 313, 316]\n",
      "[314, 313, 353, 297, 346, 347]\n",
      "[313, 382, 581, 302, 314, 353, 316, 348, 297, 298, 346, 355, 347]\n",
      "[298, 313, 355, 348, 316, 353]\n",
      "[254, 347, 576, 271, 306, 274, 242, 382, 302, 298, 581, 353, 61, 281, 314, 297, 313, 346, 348, 353, 316, 355]\n",
      "[271, 355, 346, 297, 353, 163, 281]\n",
      "[297, 355, 314, 316, 353]\n",
      "[313, 382, 302, 297, 348, 242, 316, 271, 346, 353, 355, 314, 61, 298]\n",
      "[347, 274, 576, 163, 302, 346, 316]\n",
      "[298, 348, 346, 353, 314, 302, 382, 581, 313, 316]\n",
      "[316, 355, 314, 353, 348, 346, 297, 298, 313, 581, 382, 281, 242, 306, 274, 576, 61]\n",
      "[313, 333, 355, 316, 348, 297, 353]\n",
      "[382, 581, 61, 306, 281, 274, 576]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[333, 316, 353, 314, 298, 348, 346, 313, 297, 382, 581, 274, 281, 242, 306, 576, 61, 308]\n",
      "[297, 298, 302, 353, 348, 355, 316]\n",
      "[348, 316, 355, 314, 353, 346, 313, 581, 382, 274, 281, 306, 576, 61, 298, 302, 353, 297]\n",
      "[581, 297, 382, 576, 316, 313, 348, 355, 314]\n",
      "[21, 242, 306, 61, 281, 274, 302, 581, 382, 298, 297, 313, 348, 353, 346, 314, 316, 355]\n",
      "[21, 297, 242, 314, 313, 382, 298, 355, 281, 274, 316, 61, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 313, 271]\n",
      "[254, 21, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353]\n",
      "[61, 576, 306, 242, 281, 274, 581, 382, 297, 313, 346, 348, 298, 314, 353, 355, 316]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[274, 61, 576, 382, 21, 281, 581, 297, 271, 302, 242, 313, 298, 346, 348, 355, 316, 314, 306, 353, 297, 353]\n",
      "[313, 281, 581, 382, 348, 314, 298, 355, 316, 346]\n",
      "[347, 271, 281, 382, 298, 314, 355, 353, 581, 313, 297, 346, 316, 302]\n",
      "[378, 314, 274, 61, 382, 298, 346, 163]\n",
      "[346, 314, 316, 242, 297, 353]\n",
      "[353, 314, 348, 346, 297, 313, 242, 298, 581, 382, 302, 274, 281, 576, 353, 306, 61, 271, 297, 21, 355, 316]\n",
      "[333, 297, 61, 576, 306, 274, 242, 281, 347, 581, 163, 382, 297, 313, 298, 271, 348, 353, 346, 353, 302, 314, 316, 355]\n",
      "[281, 313, 298, 346, 348, 353, 316, 314, 355]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 271, 353, 297, 346, 382, 581, 576, 306, 298, 281, 242, 302, 61, 316, 274, 355, 353, 313, 314, 348]\n",
      "[355, 581, 297, 576, 382, 348, 298, 346, 353, 314]\n",
      "[254, 21, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353]\n",
      "[347, 581, 346, 382, 298, 316, 355, 314, 313]\n",
      "[302, 242, 298, 346, 297, 348, 313, 353, 314, 355, 316]\n",
      "[297, 355, 297, 348, 353, 316, 353, 308, 271, 281, 302, 382, 298, 346, 314]\n",
      "[576, 306, 242, 274, 163, 313, 271, 302, 347, 61, 281, 297, 348, 346, 298, 353, 314, 316, 355]\n",
      "[274, 242, 382, 576, 306, 313]\n",
      "[353, 314, 355, 347, 297, 302, 297, 306, 298, 348, 316]\n",
      "[297, 271, 353, 316, 21, 576, 313]\n",
      "[297, 271, 382, 302, 581, 298, 348, 346, 353, 355]\n",
      "[347, 316, 353, 348, 346]\n",
      "[127, 21, 281, 302, 242, 298, 353, 355, 347, 576, 274, 61, 382, 581, 313, 297]\n",
      "[302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[380, 321, 371, 328, 385, 127, 378, 394, 163, 316, 271, 297, 353, 302]\n",
      "[274, 61, 306, 281, 581, 242, 382, 346, 298, 313, 348, 353, 355, 314, 297, 316]\n",
      "[61, 576, 274, 306, 281, 382, 302, 242, 581, 346, 297, 298, 348, 314, 353, 316, 355]\n",
      "[271, 314, 297, 274, 581, 302, 313, 353, 316]\n",
      "[353, 581, 302, 346, 297, 348, 353, 316, 313, 314]\n",
      "[281, 274, 242, 316, 308, 333, 314, 355, 353, 581, 298, 297, 271]\n",
      "[298, 355, 316, 314, 353]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 281, 274, 316, 61, 353, 355, 298]\n",
      "[347, 242, 346, 297, 348, 316, 355, 353, 314, 382, 313, 581, 298]\n",
      "[271, 355, 274, 281, 353, 348, 346, 302, 242, 316, 314, 313]\n",
      "[271, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[306, 61, 581, 314, 316]\n",
      "[302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 298, 355, 281, 274, 316, 61, 353]\n",
      "[316, 314, 576, 348, 306, 298, 346, 313, 382, 271, 302, 581, 274, 355]\n",
      "[297, 353, 61, 306, 576]\n",
      "[347, 576, 297, 355, 298, 313, 346, 353, 316]\n",
      "[306, 281, 61, 576, 242, 313, 353, 346, 297, 271, 348, 314, 355, 316]\n",
      "[271, 346, 581, 353, 316, 348, 313]\n",
      "[306, 274, 61, 281, 302, 297, 355, 346, 313, 242, 581, 316, 314]\n",
      "[281, 298, 581, 346, 314, 348, 316, 355, 271, 353]\n",
      "[242, 581, 316, 314, 355, 298, 353, 348, 313]\n",
      "[61, 348, 355, 316, 313, 314, 242]\n",
      "[353, 61, 313, 316, 346, 348, 355]\n",
      "[274, 581, 382, 346, 242, 281, 355, 314, 298]\n",
      "[21, 271, 281, 581, 346, 297, 348, 314, 316, 355, 298, 353, 313, 347]\n",
      "[297, 316, 274, 355, 348, 242, 313, 346, 353]\n",
      "[353, 355, 314, 348, 302, 316, 271, 297, 298, 346, 353, 382, 297, 581, 313, 242, 576, 61, 281, 306]\n",
      "[353, 297, 316, 355, 314, 61, 348, 346, 313, 298, 581, 297, 382, 353, 242, 281, 274, 306, 576, 302, 271]\n",
      "[281, 382, 314, 274, 306, 576, 242, 271, 302, 581, 298, 313, 297, 346, 353, 355, 316]\n",
      "[348, 297, 382, 581, 576, 306, 353, 298, 281, 274, 61, 316, 314, 313, 346, 242, 355]\n",
      "[61, 348, 346, 314, 353, 382, 298, 355, 316, 302, 313, 347, 297, 271, 576, 306]\n",
      "[347, 308, 298, 297, 281, 382, 581, 302, 346, 348, 316, 314, 271, 355, 353]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 353, 348, 242, 314, 313, 346, 382, 581, 576, 306, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353, 347]\n",
      "[313, 347, 297, 163, 21, 61, 274, 306, 576, 281, 271, 581, 382, 298, 346, 353, 355, 316, 302, 242, 353, 297, 313, 314, 348]\n",
      "[576, 297, 271, 297, 302, 348, 581, 298, 353, 313]\n",
      "[347, 313, 302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[254, 298, 353, 281, 316, 355]\n",
      "[347, 313, 297, 353, 346, 306, 298, 281, 348, 353, 271, 61, 274, 242, 302, 576, 581, 382, 313, 355, 297, 314, 316]\n",
      "[163, 347, 355, 302, 581, 281, 297, 382, 313]\n",
      "[61, 274, 306, 576, 281, 297, 271, 302, 581, 382, 353, 242, 298, 313, 297, 346, 348, 353, 355, 316, 314]\n",
      "[378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 353, 348, 242, 314, 313, 346, 581, 576, 306, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353, 347, 382]\n",
      "[298, 355, 281, 274, 316, 61, 353, 306, 576, 581, 382, 346, 313, 314, 242, 297, 348]\n",
      "[242, 346, 382, 581, 306, 281, 274, 316, 61, 576, 298, 313, 297, 314, 355, 353, 348]\n",
      "[353, 271, 576, 306, 61, 581, 382, 298, 313, 346, 348]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[242, 271, 382, 347, 355, 316, 302, 353, 346, 348]\n",
      "[353, 355, 314, 348, 302, 316, 271, 297, 298, 346, 353, 382, 297, 581, 313, 242, 576, 61, 281, 306]\n",
      "[314, 298, 254, 271, 353, 297, 297, 302]\n",
      "[281, 313, 298, 314, 302, 382, 297, 355, 581, 348]\n",
      "[347, 576, 281, 242, 382, 313, 298, 297, 348, 353, 355, 316, 61, 306, 274, 581, 346, 314]\n",
      "[355, 21, 298, 314, 348, 316, 353]\n",
      "[382, 313, 355, 316, 316, 353, 348, 308, 308]\n",
      "[316, 308, 333, 314, 316, 355, 353, 348, 346, 297, 313, 298, 242, 353, 382, 581, 302, 271, 297, 281, 576, 306, 274, 61]\n",
      "[353, 297, 382, 355, 316, 314]\n",
      "[254, 21, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353]\n",
      "[21, 347, 163, 271, 394, 385, 348, 297, 314, 313, 346, 382, 581, 306, 353, 298, 355, 281, 316, 61]\n",
      "[302, 297, 353, 382, 298, 61, 274, 306, 576, 281, 271, 581, 313, 242, 297, 346, 348, 353, 355, 314, 316]\n",
      "[298, 313, 302, 382, 271, 242, 353, 297, 581, 281, 576, 274, 306, 61, 297, 346, 348, 353, 355, 314, 316]\n",
      "[271, 297, 346, 355, 302, 353, 298]\n",
      "[302, 297, 271, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 353]\n",
      "[298, 313, 297, 346, 348, 302, 274, 353]\n",
      "[348, 297, 353, 306, 242, 313, 346, 576, 355, 281, 274, 61, 581, 382, 314, 316, 298, 316, 297, 271, 353, 302]\n",
      "[271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 61, 316, 297, 302]\n",
      "[297, 242, 347, 382, 302, 281, 274, 271, 348, 313, 298, 314, 355]\n",
      "[274, 576, 306, 302, 271, 281, 242, 61, 297, 382, 581, 313, 348, 314, 346, 353, 316, 298, 355]\n",
      "[297, 298, 355, 271, 316, 346, 353, 302, 581]\n",
      "[353, 353, 297, 302, 347, 61, 281, 298, 581, 313, 314, 316, 382, 346, 348, 355]\n",
      "[61, 576, 306, 242, 347, 274, 281, 382, 302, 581, 298, 313, 348, 353, 346, 316, 355]\n",
      "[382, 271, 306, 281, 274, 581, 242, 313, 314, 355, 353, 316]\n",
      "[302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[347, 313, 353, 346, 297, 314, 316, 355, 271, 382, 348, 353]\n",
      "[61, 313, 163, 394, 281, 581, 242, 274, 353, 302, 298, 346, 348, 316]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 61, 316]\n",
      "[355, 576, 281, 306, 61, 581, 242, 298]\n",
      "[298, 378, 297, 242, 302, 313, 355, 306, 274, 314, 316, 576, 281]\n",
      "[61, 316, 274, 281, 355, 298, 382, 581, 306, 346, 348, 297, 242, 314, 313, 576, 353]\n",
      "[306, 313, 382, 281, 274, 346, 61, 242, 581, 348, 314, 316]\n",
      "[576, 306, 313, 274, 581, 382, 355, 314, 316, 346, 281, 242, 298, 297, 348, 353]\n",
      "[297, 271, 353, 302, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[347, 271, 298, 302, 314, 316, 355]\n",
      "[274, 163, 61, 576, 313, 353, 355, 316, 298]\n",
      "[355, 298, 254, 271, 353]\n",
      "[313, 314, 346, 297, 316]\n",
      "[576, 271, 274, 306, 61, 581, 242, 298, 314, 316]\n",
      "[254, 348, 302, 353, 61, 382, 306, 581, 313, 281, 274, 242, 297, 346, 314, 355, 298, 316]\n",
      "[353, 242, 581, 298, 346, 281, 355, 316, 348, 302, 353, 297]\n",
      "[348, 242, 346, 382, 581, 576, 306, 353, 298, 281, 274, 316, 61, 271, 353, 302, 313, 314, 297, 355]\n",
      "[297, 313, 281, 382, 581, 298, 353, 346, 348, 355]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 271, 353, 297, 346, 382, 581, 576, 306, 298, 281, 242, 302, 61, 316, 274, 355, 353, 313, 314, 348]\n",
      "[313, 347, 21, 371, 380, 321, 385, 127, 328, 379, 394, 163, 378, 316, 274, 306, 576, 346, 242, 348, 61, 281, 382, 302, 581, 298, 313, 297, 314, 355, 353, 316]\n",
      "[274, 61, 313, 297, 346, 355, 353, 316]\n",
      "[316, 355, 353, 314, 348, 297, 346, 298, 313, 242, 581, 382, 274, 281, 576, 306, 61]\n",
      "[355, 316, 274, 581, 353, 271, 302, 313, 346, 297, 348, 353]\n",
      "[302, 297, 271, 353, 313]\n",
      "[302, 297, 271, 353, 242, 313, 382, 581, 576, 306, 298, 281, 274, 61, 346, 297, 348, 353, 355, 314, 316]\n",
      "[313, 298, 242, 348, 346, 355, 314, 316, 271, 353, 297, 302, 353]\n",
      "[302, 346, 316, 355, 314]\n",
      "[302, 382, 313, 346, 274, 281, 242, 298, 348, 353, 314, 316, 581, 355]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[313, 382, 355, 297, 353, 346]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[254, 21, 61, 242, 271, 306, 576, 353, 313, 297, 314, 348, 316, 281, 302, 355]\n",
      "[313, 347, 302, 163, 306, 576, 382, 298, 353, 355, 316, 314]\n",
      "[254, 61, 274, 306, 576, 281, 581, 382, 242, 298, 313, 297, 346, 348, 355, 314, 316, 353]\n",
      "[271, 61, 576, 306, 274, 281, 353, 242, 581, 302, 298, 313, 346, 297]\n",
      "[316, 353, 346, 313, 242, 297, 348]\n",
      "[382, 254, 347, 313, 353, 346, 314, 316]\n",
      "[394, 163, 271, 302, 298, 346, 314, 353, 581, 316, 355, 348]\n",
      "[163, 347, 297, 271, 353, 306, 61, 576, 274, 302, 281, 242, 297, 382, 581, 316, 298, 355, 313, 348, 353, 346, 314]\n",
      "[271, 306, 242, 302, 297, 316, 346, 348, 353, 355, 314]\n",
      "[302, 353, 271, 297, 382, 306, 274, 61, 281, 576, 581, 242, 313, 298, 346, 297, 348, 353, 355, 316, 314]\n",
      "[302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[297, 314, 316, 306, 382, 313, 576, 581, 302, 353, 346, 355]\n",
      "[271, 306, 576, 281, 302, 382, 581, 298, 313, 297, 348, 353, 314, 316, 355]\n",
      "[271, 382, 355, 313, 297, 353, 302, 581, 346, 316]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 271, 353, 297, 346, 382, 581, 576, 306, 298, 281, 242, 302, 61, 316, 274, 355, 353, 313, 314, 348]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[254, 302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 21]\n",
      "[347, 313, 302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 347, 313, 302, 271]\n",
      "[306, 346, 581, 382, 313, 298, 297, 348, 353, 355, 314, 316]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 353, 348, 242, 314, 313, 346, 382, 581, 576, 306, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353, 347]\n",
      "[347, 274, 306, 281, 581, 313, 382, 316, 314]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 271, 353, 297, 346, 382, 581, 576, 306, 298, 281, 242, 302, 61, 316, 274, 355, 353, 313, 314, 348]\n",
      "[274, 347, 313, 308, 333, 348, 297, 242, 314, 346, 382, 581, 576, 306, 353, 298, 355, 281, 316, 61]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 271, 353, 297, 346, 382, 581, 576, 306, 298, 281, 242, 302, 61, 316, 274, 355, 353, 313, 314, 348]\n",
      "[348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[316, 378, 163, 394, 379, 328, 127, 385, 321, 380, 371, 297, 353, 348, 242, 314, 313, 346, 382, 581, 576, 306, 298, 355, 281, 274, 316, 61, 302, 297, 271, 353, 347]\n",
      "[302, 297, 271, 353, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[314, 306, 576, 355, 348, 297, 313, 353, 346, 316]\n",
      "[271, 302, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n",
      "[306, 382, 313, 346, 348, 314, 355, 316, 297, 353, 347]\n",
      "[271, 353, 297, 61, 298, 281, 346, 316, 353, 348, 581, 297, 274, 355, 314]\n",
      "[313, 347, 302, 297, 271, 353]\n",
      "[254, 21, 347, 313, 353, 302, 271, 297, 348, 297, 242, 314, 313, 346, 382, 581, 576, 306, 353, 298, 355, 281, 274, 316, 61]\n"
     ]
    }
   ],
   "source": [
    "for playlist in playlists:\n",
    "    print(playlists[playlist]['list'])\n",
    "    for sid in playlists[playlist]['list']:\n",
    "        fre_story[sid] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    775\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"nce_loss/Slice_1:0\", shape=(?, 128), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-868cd26a2b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m   loss = tf.reduce_mean(\n\u001b[1;32m     45\u001b[0m       tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n\u001b[0;32m---> 46\u001b[0;31m                      num_sampled, vocabulary_size))\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# Construct the SGD optimizer using a learning rate of 1.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mnce_loss\u001b[0;34m(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0mremove_accidental_hits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_accidental_hits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0mpartition_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m   sampled_losses = sigmoid_cross_entropy_with_logits(\n\u001b[1;32m   1162\u001b[0m       labels=labels, logits=logits, name=\"sampled_losses\")\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36m_compute_sampled_logits\u001b[0;34m(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;31m# sampled_w has shape [num_sampled, dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0;31m# Apply X*W', which yields [batch_size, num_sampled]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m     \u001b[0msampled_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;31m# Retrieve the true and sampled biases, compute the true logits, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1891\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   2436\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2438\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    544\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 546\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Begin training.\n",
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # We must initialize all variables before we use them.\n",
    "  init.run()\n",
    "  print(\"Initialized\")\n",
    "\n",
    "  average_loss = 0\n",
    "  for step in xrange(num_steps):\n",
    "    batch_inputs, batch_labels = generate_batch(\n",
    "        batch_size, num_skips, skip_window)\n",
    "    feed_dict = {train_inputs : batch_inputs, train_labels : batch_labels}\n",
    "\n",
    "    # We perform one update step by evaluating the optimizer op (including it\n",
    "    # in the list of returned values for session.run()\n",
    "    _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    average_loss += loss_val\n",
    "\n",
    "    if step % 2000 == 0:\n",
    "      if step > 0:\n",
    "        average_loss /= 2000\n",
    "      # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "      print(\"Average loss at step \", step, \": \", average_loss)\n",
    "      average_loss = 0\n",
    "\n",
    "    # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "    if step % 10000 == 0:\n",
    "      sim = similarity.eval()\n",
    "      for i in xrange(valid_size):\n",
    "        valid_word = reverse_dictionary[valid_examples[i]]\n",
    "        top_k = 8 # number of nearest neighbors\n",
    "        nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "        log_str = \"Nearest to %s:\" % valid_word\n",
    "        for k in xrange(top_k):\n",
    "          close_word = reverse_dictionary[nearest[k]]\n",
    "          log_str = \"%s %s,\" % (log_str, close_word)\n",
    "        print(log_str)\n",
    "  final_embeddings = normalized_embeddings.eval()\n",
    "\n",
    "# Step 6: Visualize the embeddings.\n",
    "\n",
    "def plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n",
    "  assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "  plt.figure(figsize=(18, 18))  #in inches\n",
    "  for i, label in enumerate(labels):\n",
    "    x, y = low_dim_embs[i,:]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "\n",
    "  plt.savefig(filename)\n",
    "\n",
    "try:\n",
    "  from sklearn.manifold import TSNE\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "  plot_only = 500\n",
    "  low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:])\n",
    "  labels = [reverse_dictionary[i] for i in xrange(plot_only)]\n",
    "  plot_with_labels(low_dim_embs, labels)\n",
    "\n",
    "except ImportError:\n",
    "  print(\"Please install sklearn and matplotlib to visualize embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
